{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethansu/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6568202175504984\n",
      "Test Precision: 0.01190073431875324\n",
      "Test Recall: 0.5824820561694016\n",
      "Test F1 Score: 0.02332491554885048\n",
      "Test ROC AUC: 0.6199144830893135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "file_path = \"../data/processed/part-00000-0115a5ba-1db7-421c-866c-7f1446998bf2-c000.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.ffill()\n",
    "# Define categorical columns to encode\n",
    "categorical_columns = [\n",
    "    'seller_type', 'servicer_type', 'channel_type',\n",
    "    'purpose', 'property_type', 'occupancy_status', 'state', \n",
    "    'default_status', 'high_balance_loan_indicator', 'mod_indicator', \n",
    "    'homeready_indicator', 'relocation_mortgage_indicator', 'htlv_indicator', \n",
    "    'payment_deferral'\n",
    "]\n",
    "\n",
    "# Initialize LabelEncoder for categorical columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col, le in label_encoders.items():\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Select feature columns (including indexed categorical columns and numeric columns)\n",
    "feature_columns = [\n",
    "    'adjusted_remaining_time', 'num_borrowers', \n",
    "    'seller_type', 'servicer_type', 'channel_type', \n",
    "    'purpose', 'property_type', 'occupancy_status', \n",
    "    'state', 'high_balance_loan_indicator', 'mod_indicator', \n",
    "    'homeready_indicator', 'relocation_mortgage_indicator', \n",
    "    'htlv_indicator', 'payment_deferral'\n",
    "]\n",
    "\n",
    "# Define the target variable\n",
    "target_column = 'y_label'\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "X = df[feature_columns].values\n",
    "y = df[target_column].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=100)\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "presicion = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Precision: {presicion}\")\n",
    "print(f\"Test Recall: {recall}\")\n",
    "print(f\"Test F1 Score: {f1}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethansu/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:19:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.780021099234498\n",
      "Test Precision: 0.02357037782921883\n",
      "Test Recall: 0.7487268070405337\n",
      "Test F1 Score: 0.045702027868420335\n",
      "Test ROC AUC: 0.7644848145537356\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "file_path = \"../data/processed/part-00000-0115a5ba-1db7-421c-866c-7f1446998bf2-c000.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.ffill()\n",
    "\n",
    "\n",
    "# Define categorical columns to encode\n",
    "categorical_columns = [\n",
    "    'seller_type', 'servicer_type', 'channel_type',\n",
    "    'purpose', 'property_type', 'occupancy_status', 'state', \n",
    "    'default_status', 'high_balance_loan_indicator', 'mod_indicator', \n",
    "    'homeready_indicator', 'relocation_mortgage_indicator', 'htlv_indicator', \n",
    "    'payment_deferral'\n",
    "]\n",
    "\n",
    "# Initialize LabelEncoder for categorical columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col, le in label_encoders.items():\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Select feature columns (including indexed categorical columns and numeric columns)\n",
    "feature_columns = [\n",
    "    'adjusted_remaining_time', 'num_borrowers', \n",
    "    'seller_type', 'servicer_type', 'channel_type', \n",
    "    'purpose', 'property_type', 'occupancy_status', \n",
    "    'state', 'high_balance_loan_indicator', 'mod_indicator', \n",
    "    'homeready_indicator', 'relocation_mortgage_indicator', \n",
    "    'htlv_indicator', 'payment_deferral'\n",
    "]\n",
    "\n",
    "# Define the target variable\n",
    "target_column = 'y_label'\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "X = df[feature_columns].values\n",
    "y = df[target_column].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "test_dmatrix = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'silent': 1,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "bst = xgb.train(params, train_dmatrix, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = bst.predict(test_dmatrix)\n",
    "\n",
    "# Convert the predictions to binary (0 or 1)\n",
    "predictions = np.round(preds)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Precision: {precision}\")\n",
    "print(f\"Test Recall: {recall}\")\n",
    "print(f\"Test F1 Score: {f1}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "\n",
    "\n",
    "# Optional: save the model for later use\n",
    "# bst.save_model(\"xgboost_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethansu/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m220093/473921\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7:39\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.5175"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[1;32m     76\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/imcTrading/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    825\u001b[0m     _tf_function_counter\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(compiled)))\u001b[38;5;241m.\u001b[39mincrease_by(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    827\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m--> 828\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[1;32m    829\u001b[0m   \u001b[38;5;66;03m# TODO(cheshire): Do not duplicate the XLAControlFlowContext annotation.\u001b[39;00m\n\u001b[1;32m    830\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "file_path = \"../data/processed/part-00000-0115a5ba-1db7-421c-866c-7f1446998bf2-c000.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.ffill()\n",
    "\n",
    "# Define categorical columns to encode\n",
    "categorical_columns = [\n",
    "    'seller_type', 'servicer_type', 'channel_type',\n",
    "    'purpose', 'property_type', 'occupancy_status', 'state', \n",
    "    'default_status', 'high_balance_loan_indicator', 'mod_indicator', \n",
    "    'homeready_indicator', 'relocation_mortgage_indicator', 'htlv_indicator', \n",
    "    'payment_deferral'\n",
    "]\n",
    "\n",
    "# Initialize LabelEncoder for categorical columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col, le in label_encoders.items():\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Select feature columns (including indexed categorical columns and numeric columns)\n",
    "feature_columns = [\n",
    "    'adjusted_remaining_time', 'num_borrowers', \n",
    "    'seller_type', 'servicer_type', 'channel_type', \n",
    "    'purpose', 'property_type', 'occupancy_status', \n",
    "    'state', 'high_balance_loan_indicator', 'mod_indicator', \n",
    "    'homeready_indicator', 'relocation_mortgage_indicator', \n",
    "    'htlv_indicator', 'payment_deferral'\n",
    "]\n",
    "\n",
    "# Define the target variable\n",
    "target_column = 'y_label'\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "X = df[feature_columns].values\n",
    "y = df[target_column].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape the data to be suitable for LSTM (samples, timesteps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Precision: {precision}\")\n",
    "print(f\"Test Recall: {recall}\")\n",
    "print(f\"Test F1 Score: {f1}\")\n",
    "print(f\"Test ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imcTrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
