{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvgsFnpHEKsq",
        "outputId": "ffe58300-bb32-4542-9f59-1556562237ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "cKg1UKrkLP0Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preperation"
      ],
      "metadata": {
        "id": "fsoDVVo6uhic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path, chunk_size=100000):\n",
        "    chunks = []\n",
        "    dtype_dict = {\n",
        "        'LOAN_ID': str  # Ensure LOAN_ID is read as string\n",
        "        # Add other columns if specific types are known in advance\n",
        "    }\n",
        "    for chunk in pd.read_csv(file_path, chunksize=chunk_size, dtype=dtype_dict):\n",
        "        # Convert data types to reduce memory usage\n",
        "        for col in chunk.columns:\n",
        "            if chunk[col].dtype == 'float64':\n",
        "                chunk[col] = chunk[col].astype('float32')\n",
        "            elif chunk[col].dtype == 'int64':\n",
        "                chunk[col] = chunk[col].astype('int32')\n",
        "        chunks.append(chunk)\n",
        "    return pd.concat(chunks)"
      ],
      "metadata": {
        "id": "6TxTYtbMdfhO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_file_path = \"/content/drive/MyDrive/Data/train.csv\"\n",
        "# test_file_path = \"/content/drive/MyDrive/Data/test.csv\"\n",
        "# train_df = load_data(train_file_path)\n",
        "# test_df = load_data(test_file_path)"
      ],
      "metadata": {
        "id": "LSVD0t6xGLBD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_data('/content/drive/MyDrive/cleaned/2015Q1.csv8_quarters/part-00000-edea666e-1b0c-41d4-9cfd-857b9b575a4b-c000.csv')\n",
        "df = df.dropna()\n",
        "\n",
        "# Define categorical columns to encode\n",
        "categorical_columns = [\n",
        "    'seller_type', 'servicer_type', 'channel_type', 'num_borrowers',\n",
        "    'purpose', 'property_type', 'occupancy_status', 'state',\n",
        "    'default_status', 'high_balance_loan_indicator', 'mod_indicator',\n",
        "    'homeready_indicator', 'relocation_mortgage_indicator', 'htlv_indicator',\n",
        "    'payment_deferral'\n",
        "]\n",
        "\n",
        "# Initialize LabelEncoder for categorical columns\n",
        "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
        "for col, le in label_encoders.items():\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Select feature columns (including indexed categorical columns and numeric columns)\n",
        "feature_columns = [\n",
        "    'original_rate', 'orginal_credit_score', 'original_loan_to_value', 'curr_unpaid', 'adjusted_remaining_time',\n",
        "    'seller_type', 'servicer_type', 'channel_type', 'num_borrowers',\n",
        "    'purpose', 'property_type', 'occupancy_status', 'state',\n",
        "    'high_balance_loan_indicator', 'mod_indicator',\n",
        "    'homeready_indicator', 'relocation_mortgage_indicator', 'htlv_indicator',\n",
        "    'payment_deferral'\n",
        "]\n",
        "\n",
        "df['ACT_PERIOD'] = pd.to_datetime(df['ACT_PERIOD'], errors='coerce')\n",
        "train_start_date = pd.to_datetime('2015-01-01')\n",
        "train_end_date = pd.to_datetime('2019-01-01')\n",
        "test_start_date = pd.to_datetime('2021-01-01')\n",
        "test_end_date = pd.to_datetime('2022-01-01')\n",
        "train_df = df[(df['ACT_PERIOD'] >= train_start_date) & (df['ACT_PERIOD'] < train_end_date)]\n",
        "test_df = df[(df['ACT_PERIOD'] >= test_start_date) & (df['ACT_PERIOD'] < test_end_date)]\n",
        "\n",
        "# Prepare the features (X) and target (y) for train and test datasets\n",
        "X_train = train_df[feature_columns].values\n",
        "y_train = train_df['y_label'].values\n",
        "X_test = test_df[feature_columns].values\n",
        "y_test = test_df['y_label'].values\n",
        "\n",
        "# Define the target variable\n",
        "target_column = 'y_label'\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "tMnm1d7RaP-Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-J_DFQEj1zq",
        "outputId": "d041ca4a-82fd-4175-aa70-cfc4dd0717f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LOAN_ID', 'ACT_PERIOD', 'original_rate', 'orginal_credit_score',\n",
              "       'original_loan_to_value', 'curr_unpaid', 'seller_type', 'servicer_type',\n",
              "       'channel_type', 'adjusted_remaining_time', 'num_borrowers', 'purpose',\n",
              "       'property_type', 'occupancy_status', 'state', 'default_status',\n",
              "       'mod_indicator', 'homeready_indicator', 'relocation_mortgage_indicator',\n",
              "       'high_balance_loan_indicator', 'htlv_indicator', 'payment_deferral',\n",
              "       'y_label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxrVJkfQD7Cv"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model on the training data\n",
        "log_reg.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Test Precision: {precision}\")\n",
        "print(f\"Test Recall: {recall}\")\n",
        "print(f\"Test F1 Score: {f1}\")\n",
        "print(f\"Test ROC AUC: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shTpIvuWt4H3",
        "outputId": "be0a38ad-df42-4d08-c415-22489c4f3a74"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6984406325028056\n",
            "Test Precision: 0.006615373140322793\n",
            "Test Recall: 0.7215269086357947\n",
            "Test F1 Score: 0.013110541307301764\n",
            "Test ROC AUC: 0.7099516359143574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xee7XIqRD7Cx"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "2ecTRnb9J2sN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribution of classes in train set:\", np.bincount(y_train))\n",
        "print(\"Distribution of classes in test set:\", np.bincount(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsLcPLYEHxhB",
        "outputId": "8b325105-045d-4039-cfa9-a933abcb05e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of classes in train set: [16759907   104766]\n",
            "Distribution of classes in test set: [1722060    4794]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rDxaFY8kD7Cx",
        "outputId": "ea85f277-1a67-4f7a-ae7b-cbaac970faa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [21:30:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6692499771260338\n",
            "Test Precision: 0.006471019834817329\n",
            "Test Recall: 0.7745098039215687\n",
            "Test F1 Score: 0.012834805032294417\n",
            "Test ROC AUC: 0.789064722722891\n"
          ]
        }
      ],
      "source": [
        "xgb_model = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    max_depth = 6,\n",
        "    learning_rate=0.03,\n",
        "    n_jobs=-1,        # Uses all available threads, similar to nthread=-1\n",
        "    scale_pos_weight=160,  # Handling imbalance in the dataset\n",
        "    use_label_encoder=False  # To avoid warning, as the label encoder is deprecated\n",
        ")\n",
        "\n",
        "# Train the XGBClassifier\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "preds = xgb_model.predict_proba(X_test)[:, 1]\n",
        "predictions = np.round(preds)  # Convert probabilities to binary (0 or 1)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "roc_auc = roc_auc_score(y_test, preds)  # Use probability for ROC AUC\n",
        "\n",
        "# Print performance metrics\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Test Precision: {precision}\")\n",
        "print(f\"Test Recall: {recall}\")\n",
        "print(f\"Test F1 Score: {f1}\")\n",
        "print(f\"Test ROC AUC: {roc_auc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(0.1, 0.91, 0.05)\n",
        "\n",
        "best_threshold = 0\n",
        "best_roc_auc = 0\n",
        "results_dict = {}\n",
        "\n",
        "for threshold in thresholds:\n",
        "    # Convert probabilities to binary predictions based on the current threshold\n",
        "    predictions = (preds >= threshold).astype(int)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    roc_auc = roc_auc_score(y_test, preds)  # ROC AUC is calculated on probabilities\n",
        "\n",
        "    # Save metrics for each threshold in the dictionary\n",
        "    results_dict[threshold] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "print(\"\\nAll Results:\")\n",
        "for thresh, metrics in results_dict.items():\n",
        "    print(f\"Threshold {thresh}:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "Ovkfa37ZZT60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA4lsqeaD7Cy"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMTbvmWiD7Cy"
      },
      "outputs": [],
      "source": [
        "X_train_smote = X_train_smote.reshape((X_train_smote.shape[0], 1, X_train_smote.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(X_train_smote.shape[1], X_train_smote.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_smote, y_train_smote, epochs=10, batch_size=128, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Test Precision: {precision}\")\n",
        "print(f\"Test Recall: {recall}\")\n",
        "print(f\"Test F1 Score: {f1}\")\n",
        "print(f\"Test ROC AUC: {roc_auc}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}